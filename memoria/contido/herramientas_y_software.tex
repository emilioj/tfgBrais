\chapter{Herramientas y Software}
\label{chap:hs}
En este capítulo se explican las herramientas y librerías utilizadas para llevar a cabo el proyecto.
\section{Lenguajes de programación}
    \paragraph{C++}~\\
    El proyecto se desarrolló en su totalidad en C++. Esto se debe a que, como se menciona previamente, este trabajo forma parte del esfuerzo académico de \citeauthor{IglesiasGuitian2022} y por coherencia se decidió seguir la línea de trabajo.
C++ es un lenguaje de programación que se beneficia de programación orientada a objetos sobre la sintaxis de C y se ha utilizado para implementar librerías gráficas intrínsecas en el proyecto. C++ es el lenguaje de programación predominante en aplicaciones interactivas de alto rendimiento.

\section{Sistema Operativo}
\paragraph{Windows 11}~\\
Windows 11 es un sistema operativo desarrollado por Microsoft. Se utilizó debido a la familiaridad del proyecto con el mismo.
\section{Control de versiones}
    \paragraph{Git y GitLab}~\\
Para llevar a cabo el control de versiones se utilizó Git, manteniendo un repositorio remoto en el servicio web GitLab.
\section{Entorno de desarrollo}
    \paragraph{Visual Studio Community}~\\
Para la programación se optó por este IDE de Microsoft, que ofrece muchas facilidades para un desarrollo eficiente en C++ en Windows.
\section{Herramientas}
    \paragraph{DICOM}~\\
    \acrshort{dicom} es la denominación de un estándar utilizado principalmente para la visualización, impresión, almacenamiento y transmisión de imágenes y datos de propósito médico.
    Los ficheros \acrshort{dicom} consisten en una cabecera con campos estandarizados y de forma libre, y un cuerpo con datos de imagen. Un objeto \acrshort{dicom} simple puede contener solamente una imagen, pero esta imagen puede tener múltiples fotogramas, permitiendo el almacenamiento de bloques de datos con varios fotogramas.
   
    \paragraph{3D Slicer}~\\
3D Slicer es un programa de software libre diseñado para solventar los problemas más avanzados de la computación de imagen relacionados con las aplicaciones clínicas y biométricas. Entre las capacidades del mismo se encuentra la posibilidad de implementar scripts de Python, segmentación de imágenes y volúmenes, la posibilidad de añadir extensiones para aumentar su funcionalidad y la interoperabilidad del estándar \acrshort{dicom}, entre otras.

\paragraph{Meshmixer}~\\
Al procurar generar un modelo a partir de una nube de puntos de un TAC, es común encontrarse con que los modelos exportados en STL contienen errores y no pueden ser impresos directamente. Se probaron varias herramientas para solventar estos errores en la estructura de los modelos 3D, pero finalmente \href{https://www.meshmixer.com}{Meshmixer} resultó dar los mejores resultados a la hora de arreglar las geometrías con esta casuística tan específica.
    \paragraph{Meshlab}~\\
Una alternativa de software libre para la reparación de mallas 3D es \href{https://www.meshlab.net}{Meshlab}, que ofrece herramientas similares para limpiar y corregir geometrías de modelos STL.
    \paragraph{Blender}~\\
Blender es un potente software de modelado, animación, renderizado y edición 3D de código abierto y gratuito. Ofrece una suite completa de herramientas para la creación y manipulación de modelos 3D, incluyendo texturizado, iluminación, simulación física y composición. En este proyecto, se utilizó para procesar y refinar modelos 3D generados a partir de imágenes médicas, aprovechando su flexibilidad para trabajar con formatos como STL y OBJ, y su capacidad para integrar scripts en Python para automatizar tareas.
    \paragraph{UltiMaker Cura}~\\
UltiMaker Cura es el programa desarrollado por UltiMaker para generar el GCODE necesario para imprimir modelos en una impresora de dicha marca. Se utilizó ya que permite importar ajustes específicos de la impresora sobre la que se trabajó de forma sencilla.
\section{APIs, frameworks y bibliotecas software}
\subsection{OpenXR}
OpenXR es una \acrfull{api} multiplataforma que permite el desarrollo de medios en el \textit{virtual continuum} mediante ordenadores a través de interacción humano-máquina.
Esta \acrshort{api} es la interfaz con un runtime para llevar a cabo operaciones comunes como puede ser acceder al estado de un mando o periférico, obtener o predecir la posición del sistema o enviar frames para ser renderizados.

\subsubsection{Ciclo de Vida de un proyecto OpenXR}
En la \figurename~\ref{fig:openxrlifecycle} se muestra la máquina de estados de la sesión:
\begin{enumerate}
    \item La aplicación crea una sesión escogiendo un sistema y una API gráfica. En un primer momento esta se encuentra en estado IDLE.
    \item Se monitorea la sesión en busca de cambios de estados mediante eventos.
    \item Cuando el runtime determina que el sistema está listo para empezar con el contenido \acrshort{xr} de la sesión, se recibe un cambio de estado a READY.
    \item Mientras que la sesión está corriendo, se espera que la aplicación ejecute continuamente el frame loop, estableciendo así sincronización con el runtime, lo que provoca un cambio de estado a SYNCHRONIZED.
    \item Una vez que el runtime esté listo para mostrar frames de la aplicación, se notifica con el estado VISIBLE.
    \item Si el runtime detecta que es posible recibir entradas desde un mando, reconocimiento facial o demás, notifica con un estado FOCUSED.
    \item Estos estados, como se ve en la \figurename~\ref{fig:openxrlifecycle}, también tienen carácter retroactivo, de forma que cuando las características dejan de estar disponibles se va cambiando de estado, hasta que se desee parar o cerrar la aplicación.
    
\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{imaxes/openXR_life_cycle.png}
  \caption{Ciclo de vida de OpenXR. (fuente: \href{https://www.khronos.org/}{https://www.khronos.org/})}
  \label{fig:openxrlifecycle}
\end{figure}

\subsubsection{API Layers}
OpenXR está diseñado como una \acrshort{api} por capas, lo que quiere decir que una aplicación puede insertar más o menos capas entre la aplicación y la implementación del runtime seleccionada. Estas capas proveen de funcionalidades adicionales interceptando las funciones de OpenXR de la capa superior, y posteriormente llevando a cabo operaciones distintas a las que se llevarían a cabo en caso de que no estuviese presente la capa. En el más sencillo de los casos una capa simplemente llama a la inferior con los mismos argumentos, pero en casos más elaborados se pueden implementar funcionalidades no disponibles en las capas o incluso runtime inferiores (\figurename~\ref{fig:openxrapilayer}).

Esta arquitectura permite el desarrollo multiplataforma con mayor simplicidad, pero es dependiente de que los vendedores implementen sus propias capas API de OpenXR, lo que limita en cierta medida las posibilidades de desarrollo. 

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{imaxes/openxr_api_layer_graph.png}
  \caption{Explicación de la API por capas. (fuente: \href{https://registry.khronos.org/OpenXR/specs/1.0/loader.html}{https://registry.khronos.org})}
  \label{fig:openxrapilayer}
\end{figure}

\subsection{OpenCV}
\acrfull{opencv} es una librería de código abierto que implementa principalmente funciones de visión artificial en tiempo real. Se utilizó para la generación y el seguimiento de los marcadores ArUco que forma parte de los paquetes adicionales de la librería.

\subsection{OpenSceneGraph}
\acrfull{osg} es una librería gráfica 3D de código abierto escrita en C++ que encapsula la funcionalidad de OpenGL mediante una arquitectura basada en grafos de escena. Esta estructura permite organizar eficientemente objetos 3D, transformaciones y materiales en aplicaciones de renderizado en tiempo real.

En este proyecto, \acrshort{osg} se utiliza para renderizar la interfaz de usuario en modo VR, proporcionando las herramientas necesarias para interactuar con la visualización en el entorno de realidad virtual.

\subsection{Assimp}
\acrfull{assimp} es una librería multiplataforma de código abierto diseñada para importar múltiples formatos de modelos 3D. La librería soporta decenas de formatos de archivo diferentes incluyendo FBX, OBJ, 3DS, DAE, entre otros. En este proyecto se utiliza para cargar modelos 3D anatómicos generados a partir de imágenes de \acrshort{tc}, proporcionando una interfaz consistente para acceder a geometrías, texturas y materiales independientemente del formato de archivo original.

\subsection{GLFW}
\acrfull{glfw} es una librería multiplataforma de código abierto para desarrollo de aplicaciones OpenGL, OpenGL ES y Vulkan. Proporciona una \acrshort{api} simple para crear ventanas, contextos y superficies, recibir entradas y eventos. En este proyecto se utiliza para la gestión de ventanas de renderizado y la creación de contextos OpenGL necesarios para la visualización de modelos 3D en tiempo real.

\subsection{GLEW}
\acrfull{glew} es una librería multiplataforma de código abierto que ayuda en la consulta y carga de extensiones OpenGL. GLEW proporciona mecanismos para determinar qué extensiones OpenGL están soportadas en la plataforma objetivo, simplificando el uso de OpenGL. En este proyecto se utiliza para acceder a características de OpenGL necesarias para el renderizado de modelos 3D con shaders programables.

\subsection{GLM}
\acrfull{glm} es una librería de matemáticas C++ diseñada específicamente para gráficos por computador basada en las especificaciones OpenGL Shading Language (GLSL). Proporciona clases y funciones para operaciones con vectores, matrices y transformaciones 3D. En este proyecto se utiliza para realizar cálculos de transformaciones geométricas, proyecciones de cámara y manipulación de matrices necesarias para el correcto posicionamiento de modelos 3D en el espacio de realidad aumentada.

\subsection{ArUco}
Los últimos años, los desarrollos de nuevos marcadores han tendido a un cuadrado negro con distintos patrones interiores, como en el ejemplo de la \figurename~\ref{fig:qrtags}, ya que permiten extraer la pose de la cámara a partir de sus 4 esquinas, asumiendo que esta esté adecuadamente calibrada \cite{GarridoJurado2014}. Esencialmente estos marcadores comparten ciertas características comunes en cuanto a su funcionamiento, entre todas las opciones disponibles se escogió ArUco como solución a nuestro proyecto por varios motivos:
\begin{itemize}
    \item Diccionarios generados dinámicamente.
    \item Posibilidad de crear tablas de marcadores lo que incrementa la resistencia a las oclusiones.
    \item Software para la calibración de cámara: De forma sencilla se puede calibrar cualquier cámara.
    \item La librería ha soportado el paso de los años sin problema, existiendo ejemplos y documentación extensa sobre el funcionamiento de la misma, facilitando así el desarrollo.
\end{itemize}

\begin{figure}
  \centering
  \includegraphics[width=0.2\textwidth]{imaxes/qr.png}
  \caption{Marcador Generado con ArUco}
  \label{fig:qr}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{imaxes/qrtags.png}
  \caption{Ejemplos de marcadores fiduciarios previos (fuente: \cite{GarridoJurado2014})}
  \label{fig:qrtags}
\end{figure}

%\subsection{Funcionamiento de ArUco}

\paragraph{Captura de imágenes o videos con ArUco}~\\
La captura de imágenes o vídeos se realiza mediante un dispositivo específico, como una cámara digital o un dispositivo móvil con cámara incorporada. En este paso se espera obtener una serie de imágenes o un vídeo sobre el que se espera encontrar uno o varios marcadores ArUco.
\paragraph{Conversión a escala de grises}~\\
La conversión a escala de grises se realiza mediante el algoritmo de promedio ponderado de los canales RGB. Esta conversión reduce la cantidad de información a procesar y mejora la velocidad de procesamiento al trabajar con un único canal de información.
\paragraph{Aplicación de un filtro de bordes}~\\
Para resaltar los bordes de los marcadores en la imagen se aplica un filtro de bordes. Un ejemplo común es el algoritmo de Canny, que se basa en la detección de gradientes y utiliza un umbral para determinar que bordes son relevantes y cuales no.
\paragraph{Detección de contornos}~\\
Se utiliza un algoritmo de detección de contornos adaptativo para encontrar los contornos de los marcadores en la imagen. Un algoritmo común es el Transformada de Hough que permite detectar contornos circulares y lineales en la imagen. Este algoritmo busca patrones en la imagen que se correspondan con los contornos de los marcadores ArUco.
En un sistema de thresholding tradicional, se elige un umbral global para toda la imagen. Cualquier píxel con un valor de brillo superior al umbral se considera activo (p.ej. negro) y cualquier píxel con un valor de brillo inferior al umbral se considera inactivo (p.ej. blanco). Sin embargo, en muchas imágenes, el nivel óptimo de umbral puede variar entre diferentes partes de la imagen. El thresholding adaptativo se utiliza para solucionar este problema.

El thresholding adaptativo se divide en dos pasos:
\begin{itemize}
\item Selección de una región de interés (ROI) en la imagen. Esta región puede ser de cualquier tamaño y forma.
\item Selección del umbral para cada pixel dentro de la ROI. El umbral se calcula a partir de la distribución de los niveles de gris dentro de la ROI.
\end{itemize}

Existen varios métodos para calcular el umbral adaptativo, algunos de los mas conocidos son:
\begin{itemize}
\item Método de media global
\item Método de la desviación estándar
\item Método de Otsu
\end{itemize}
Cada uno de estos métodos tiene sus propios pros y contras y en función de la aplicación y el tipo de imagen, se puede elegir uno u otro.
Además es posible modificar los siguientes parámetros para adecuar la librería a nuestro caso de uso, los más importantes son:
\begin{itemize}
    \item   \textbf{markerBorderBits:}
    El número de bits que se utilizan para representar el borde de un marcador. El borde de un marcador es el área blanca que rodea el patrón de código de barras en un marcador ArUco. El valor predeterminado es 4.
    \item \textbf{adaptiveThreshWinSizeMin and adaptiveThreshWinSizeMax:}
    El tamaño mínimo y máximo de la ventana utilizada para la umbralización adaptativa. La umbralización adaptativa es un método para determinar automáticamente el valor de umbral óptimo para una imagen. Estos parámetros se utilizan para especificar el tamaño de la ventana en píxeles que se utilizará para la umbralización adaptativa.
    \item \textbf{adaptiveThreshWinSizeMax:}
    Especifica el paso o incremento con el cual se variará el tamaño de la ventana utilizada en la umbralización adaptativa.
    \item \textbf{adaptiveThreshConstant:}
    Especifica una constante que se utilizará en el cálculo del valor de umbral para cada subregión de la imagen.
    \item \textbf{minMarkerPerimeterRate and maxMarkerPerimeterRate:}
    El porcentaje mínimo y máximo del perímetro de un marcador en relación con su área. Estos parámetros se utilizan para especificar el tamaño mínimo y máximo de los marcadores que se detectarán en la imagen.
    \item \textbf{minCornerDistanceRate:}
    La relación entre la distancia entre las esquinas de un marcador y su longitud de lado. Esto es utilizado para ignorar marcadores que tengan esquinas muy cercanas entre sí.
    \item \textbf{minDistanceToBorder:}
    La distancia mínima desde el borde de la imagen hasta el borde de un marcador. Esto se utiliza para ignorar marcadores que estén demasiado cerca del borde de la imagen.
    \item \textbf{ minMarkerDistanceRate:}
    La relación entre la distancia entre los marcadores y su longitud de lado. Esto se utiliza para ignorar marcadores que estén demasiado cerca entre sí.
\end{itemize}

\paragraph{Extracción de Bits}~\\
Los bits extraídos de cada candidato se analizan para determinar si corresponden a marcadores válidos.
Para ello se somete cada sección de la imagen a una corrección de perspectiva. A continuación se subdivide el candidato en la cantidad previamente establecida en el diccionario de bits que componen cada marcador. La imagen corregida se binariza utilizando el \gls{otsu} para separar píxeles blancos y negros. Posteriormente, la imagen se divide en una cuadrícula con el mismo número de celdas que bits tiene el marcador. En cada celda se cuenta el número de píxeles blancos y negros para determinar el valor del bit asignado a dicha celda (mediante el valor mayoritario), como en el ejemplo de la \figurename~\ref{fig:mbe}.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{imaxes/marker_bits_extraction.png}
  \caption{Proceso de extracción de Bits}\label{fig:mbe}
\end{figure}

\paragraph{Identificación de Marcadores}~\\
Se verifica si el código extraído pertenece al diccionario y, en caso necesario, se aplican algoritmos de corrección de errores.
La primera operación consiste en determinar la cantidad de bits erróneos permitidos en el borde de un marcador, ya que todos los marcadores ArUco cuentan al menos con un bit de borde. En lo que a corrección de errores se refiere, cada diccionario cuenta con un límite teórico de bits que pueden ser corregidos.

\paragraph{Refinado de Esquinas}~\\
Se puede realizar un refinado a nivel de subpíxel de las esquinas para mejorar la precisión del sistema. Este último paso implica una alta carga computacional, pero se recomienda en aplicaciones en las que prima la precisión como es el caso.

Esta librería trabaja con un \gls{pinhole} lo que quiere decir que se considera como el origen de coordenadas el punto en el que todos los rayos de luz convergerían en una supuesta cámara estenopeica ideal.

Las coordenadas se definen de la siguiente forma: Z crece frente a la cámara mientras que X e Y se encuentran en el plano ortogonal de Z. X aumenta de izquierda a derecha e Y de abajo a arriba.







\section{Hardware}
\subsection{Impresión 3D}
Se utilizaron dos impresoras 3D a lo largo del proyecto puesto que eran necesarios distintos requisitos para cada pieza.
Los modelos anatómicos debido a su complejidad se imprimieron en una impresora Fuse 1+ 30W que utiliza polvo de nylon para llevar a cabo las piezas.
Para los marcadores fiduciarios, se utilizó la Ultimaker 3, ya que se trata de figuras más simples en las que la posibilidad de imprimir en distintos colores era especialmente importante.

\subsection{Equipamiento de \gls{vr}}
Se trabajó, principalmente, con el \acrshort{hmd} HTC Vive Pro 2.

\subsection{Obtención de vídeo}
Inicialmente se intentaron utilizar las cámaras frontales integradas del HTC Vive Pro 2 para esta función, pero debido a limitaciones técnicas en el acceso nativo a las cámaras (como se detalla en la Sección~\ref{subsec:captura_imagen}), se optó por utilizar una cámara externa.

\paragraph{Logitech Brio 500}~\\
La Logitech Brio 500 es una cámara web de alta calidad que ofrece grabación en HD a 60 fps. Esta cámara fue utilizada para la captura de imágenes y video en el desarrollo del sistema de realidad aumentada, proporcionando la entrada visual necesaria para el seguimiento de marcadores ArUco y la calibración del sistema. 



